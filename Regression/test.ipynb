{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "tensor([-0.2897], grad_fn=<AddBackward0>)\n",
      "tensor([-0.2897], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "x = torch.tensor([1.])\n",
    "print(x)\n",
    "model = nn.Linear(1,1)\n",
    "#print(model.weight)\n",
    "#print(model.bias)\n",
    "print(model(x))\n",
    "y = x @ model.weight + model.bias # perceptron why? entropy\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2387], grad_fn=<AddBackward0>)\n",
      "tensor([0.2387], grad_fn=<AddBackward0>)\n",
      "tensor([-0.7397], grad_fn=<AddBackward0>)\n",
      "tensor([-0.7069], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "fc1 = nn.Linear(1,100)\n",
    "fc2 = nn.Linear(100,1)\n",
    "\n",
    "x = torch.tensor([1.])\n",
    "print(fc2(fc1(x)))\n",
    "\n",
    "y = (x @ fc1.weight.T + fc1.bias) @ fc2.weight.T + fc2.bias\n",
    "print(y)\n",
    "\n",
    "model = nn.Sequential(nn.Linear(1,100), \n",
    "                      nn.Linear(100,1))\n",
    "print(model(x))\n",
    "\n",
    "\n",
    "class my_model(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.my_layer = nn.Sequential(nn.Linear(1,100), \n",
    "                                      nn.Linear(100,1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.my_layer(x)\n",
    "        return x\n",
    "\n",
    "model = my_model()\n",
    "x = torch.tensor([1.])\n",
    "y = model(x)\n",
    "print(y)\n",
    "\n",
    "\"\"\"\n",
    "# 01 \n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([331, 6]) torch.Size([83, 6]) torch.Size([331, 1]) torch.Size([83, 1])\n",
      "epoch: 0, train_loss: 2.23, my_loss: 2.23\n",
      "epoch: 1, train_loss: -197.334, my_loss: -inf\n",
      "epoch: 2, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 3, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 4, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 5, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 6, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 7, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 8, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 9, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 10, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 11, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 12, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 13, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 14, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 15, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 16, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 17, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 18, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 19, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 20, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 21, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 22, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 23, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 24, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 25, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 26, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 27, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 28, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 29, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 30, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 31, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 32, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 33, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 34, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 35, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 36, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 37, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 38, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 39, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 40, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 41, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 42, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 43, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 44, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 45, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 46, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 47, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 48, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 49, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 50, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 51, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 52, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 53, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 54, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 55, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 56, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 57, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 58, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 59, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 60, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 61, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 62, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 63, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 64, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 65, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 66, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 67, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 68, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 69, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 70, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 71, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 72, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 73, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 74, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 75, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 76, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 77, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 78, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 79, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 80, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 81, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 82, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 83, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 84, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 85, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 86, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 87, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 88, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 89, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 90, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 91, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 92, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 93, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 94, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 95, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 96, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 97, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 98, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 99, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 100, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 101, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 102, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 103, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 104, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 105, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 106, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 107, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 108, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 109, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 110, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 111, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 112, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 113, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 114, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 115, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 116, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 117, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 118, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 119, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 120, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 121, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 122, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 123, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 124, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 125, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 126, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 127, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 128, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 129, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 130, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 131, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 132, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 133, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 134, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 135, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 136, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 137, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 138, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 139, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 140, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 141, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 142, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 143, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 144, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 145, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 146, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 147, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 148, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 149, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 150, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 151, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 152, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 153, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 154, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 155, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 156, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 157, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 158, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 159, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 160, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 161, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 162, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 163, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 164, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 165, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 166, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 167, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 168, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 169, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 170, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 171, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 172, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 173, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 174, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 175, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 176, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 177, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 178, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 179, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 180, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 181, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 182, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 183, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 184, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 185, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 186, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 187, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 188, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 189, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 190, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 191, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 192, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 193, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 194, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 195, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 196, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 197, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 198, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 199, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 200, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 201, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 202, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 203, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 204, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 205, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 206, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 207, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 208, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 209, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 210, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 211, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 212, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 213, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 214, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 215, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 216, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 217, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 218, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 219, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 220, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 221, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 222, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 223, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 224, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 225, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 226, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 227, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 228, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 229, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 230, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 231, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 232, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 233, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 234, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 235, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 236, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 237, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 238, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 239, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 240, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 241, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 242, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 243, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 244, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 245, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 246, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 247, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 248, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 249, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 250, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 251, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 252, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 253, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 254, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 255, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 256, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 257, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 258, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 259, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 260, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 261, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 262, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 263, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 264, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 265, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 266, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 267, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 268, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 269, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 270, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 271, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 272, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 273, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 274, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 275, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 276, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 277, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 278, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 279, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 280, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 281, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 282, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 283, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 284, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 285, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 286, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 287, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 288, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 289, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 290, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 291, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 292, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 293, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 294, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 295, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 296, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 297, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 298, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 299, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 300, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 301, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 302, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 303, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 304, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 305, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 306, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 307, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 308, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 309, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 310, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 311, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 312, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 313, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 314, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 315, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 316, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 317, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 318, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 319, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 320, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 321, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 322, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 323, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 324, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 325, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 326, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 327, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 328, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 329, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 330, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 331, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 332, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 333, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 334, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 335, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 336, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 337, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 338, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 339, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 340, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 341, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 342, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 343, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 344, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 345, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 346, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 347, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 348, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 349, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 350, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 351, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 352, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 353, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 354, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 355, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 356, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 357, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 358, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 359, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 360, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 361, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 362, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 363, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 364, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 365, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 366, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 367, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 368, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 369, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 370, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 371, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 372, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 373, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 374, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 375, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 376, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 377, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 378, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 379, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 380, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 381, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 382, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 383, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 384, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 385, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 386, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 387, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 388, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 389, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 390, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 391, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 392, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 393, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 394, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 395, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 396, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 397, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 398, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 399, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 400, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 401, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 402, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 403, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 404, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 405, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 406, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 407, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 408, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 409, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 410, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 411, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 412, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 413, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 414, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 415, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 416, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 417, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 418, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 419, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 420, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 421, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 422, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 423, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 424, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 425, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 426, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 427, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 428, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 429, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 430, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 431, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 432, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 433, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 434, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 435, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 436, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 437, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 438, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 439, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 440, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 441, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 442, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 443, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 444, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 445, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 446, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 447, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 448, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 449, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 450, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 451, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 452, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 453, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 454, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 455, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 456, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 457, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 458, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 459, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 460, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 461, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 462, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 463, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 464, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 465, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 466, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 467, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 468, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 469, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 470, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 471, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 472, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 473, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 474, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 475, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 476, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 477, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 478, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 479, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 480, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 481, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 482, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 483, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 484, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 485, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 486, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 487, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 488, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 489, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 490, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 491, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 492, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 493, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 494, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 495, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 496, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 497, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 498, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 499, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 500, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 501, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 502, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 503, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 504, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 505, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 506, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 507, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 508, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 509, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 510, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 511, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 512, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 513, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 514, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 515, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 516, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 517, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 518, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 519, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 520, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 521, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 522, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 523, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 524, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 525, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 526, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 527, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 528, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 529, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 530, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 531, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 532, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 533, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 534, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 535, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 536, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 537, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 538, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 539, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 540, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 541, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 542, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 543, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 544, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 545, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 546, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 547, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 548, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 549, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 550, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 551, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 552, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 553, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 554, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 555, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 556, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 557, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 558, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 559, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 560, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 561, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 562, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 563, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 564, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 565, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 566, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 567, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 568, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 569, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 570, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 571, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 572, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 573, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 574, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 575, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 576, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 577, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 578, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 579, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 580, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 581, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 582, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 583, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 584, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 585, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 586, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 587, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 588, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 589, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 590, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 591, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 592, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 593, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 594, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 595, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 596, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 597, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 598, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 599, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 600, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 601, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 602, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 603, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 604, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 605, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 606, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 607, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 608, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 609, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 610, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 611, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 612, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 613, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 614, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 615, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 616, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 617, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 618, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 619, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 620, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 621, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 622, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 623, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 624, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 625, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 626, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 627, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 628, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 629, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 630, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 631, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 632, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 633, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 634, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 635, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 636, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 637, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 638, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 639, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 640, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 641, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 642, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 643, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 644, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 645, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 646, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 647, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 648, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 649, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 650, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 651, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 652, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 653, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 654, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 655, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 656, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 657, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 658, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 659, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 660, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 661, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 662, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 663, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 664, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 665, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 666, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 667, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 668, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 669, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 670, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 671, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 672, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 673, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 674, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 675, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 676, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 677, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 678, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 679, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 680, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 681, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 682, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 683, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 684, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 685, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 686, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 687, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 688, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 689, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 690, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 691, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 692, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 693, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 694, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 695, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 696, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 697, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 698, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 699, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 700, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 701, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 702, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 703, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 704, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 705, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 706, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 707, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 708, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 709, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 710, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 711, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 712, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 713, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 714, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 715, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 716, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 717, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 718, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 719, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 720, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 721, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 722, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 723, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 724, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 725, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 726, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 727, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 728, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 729, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 730, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 731, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 732, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 733, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 734, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 735, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 736, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 737, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 738, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 739, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 740, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 741, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 742, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 743, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 744, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 745, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 746, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 747, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 748, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 749, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 750, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 751, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 752, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 753, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 754, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 755, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 756, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 757, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 758, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 759, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 760, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 761, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 762, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 763, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 764, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 765, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 766, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 767, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 768, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 769, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 770, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 771, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 772, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 773, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 774, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 775, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 776, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 777, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 778, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 779, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 780, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 781, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 782, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 783, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 784, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 785, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 786, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 787, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 788, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 789, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 790, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 791, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 792, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 793, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 794, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 795, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 796, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 797, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 798, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 799, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 800, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 801, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 802, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 803, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 804, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 805, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 806, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 807, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 808, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 809, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 810, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 811, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 812, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 813, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 814, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 815, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 816, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 817, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 818, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 819, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 820, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 821, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 822, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 823, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 824, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 825, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 826, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 827, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 828, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 829, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 830, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 831, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 832, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 833, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 834, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 835, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 836, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 837, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 838, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 839, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 840, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 841, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 842, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 843, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 844, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 845, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 846, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 847, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 848, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 849, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 850, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 851, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 852, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 853, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 854, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 855, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 856, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 857, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 858, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 859, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 860, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 861, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 862, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 863, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 864, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 865, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 866, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 867, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 868, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 869, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 870, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 871, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 872, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 873, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 874, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 875, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 876, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 877, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 878, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 879, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 880, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 881, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 882, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 883, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 884, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 885, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 886, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 887, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 888, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 889, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 890, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 891, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 892, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 893, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 894, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 895, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 896, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 897, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 898, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 899, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 900, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 901, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 902, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 903, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 904, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 905, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 906, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 907, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 908, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 909, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 910, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 911, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 912, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 913, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 914, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 915, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 916, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 917, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 918, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 919, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 920, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 921, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 922, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 923, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 924, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 925, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 926, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 927, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 928, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 929, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 930, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 931, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 932, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 933, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 934, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 935, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 936, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 937, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 938, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 939, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 940, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 941, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 942, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 943, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 944, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 945, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 946, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 947, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 948, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 949, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 950, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 951, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 952, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 953, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 954, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 955, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 956, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 957, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 958, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 959, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 960, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 961, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 962, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 963, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 964, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 965, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 966, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 967, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 968, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 969, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 970, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 971, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 972, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 973, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 974, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 975, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 976, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 977, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 978, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 979, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 980, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 981, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 982, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 983, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 984, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 985, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 986, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 987, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 988, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 989, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 990, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 991, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 992, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 993, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 994, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 995, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 996, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 997, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 998, train_loss: -3686.767, my_loss: -inf\n",
      "epoch: 999, train_loss: -3686.767, my_loss: -inf\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as func\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 01 loading dataset and make tensor\n",
    "csv_file = pd.read_csv('Real_estate.csv')\n",
    "csv_file.drop('No', inplace=True, axis=1)\n",
    "y = csv_file['Y house price of unit area']\n",
    "x = csv_file.drop('Y house price of unit area', axis=1) \n",
    "#print(x.shape, y.shape)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.2, random_state=3, shuffle=True)\n",
    "#print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "X_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "Y_train = torch.tensor(Y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "Y_test = torch.tensor(Y_test.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "\n",
    "\"\"\"\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "print(pd.DataFrame({'Y_test':Y_test, 'Y_predict':y_predict}).head())\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# 02 make model\n",
    "class my_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.my_layer = nn.Sequential(nn.Linear(6, 30),\n",
    "                                      nn.Sigmoid(),\n",
    "                                      nn.Linear(30, 100),\n",
    "                                      nn.Linear(100, 80),\n",
    "                                      nn.Linear(80, 1),\n",
    "                                      nn.Sigmoid())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.my_layer(x)\n",
    "        return x\n",
    "\n",
    "model = my_model()\n",
    "\n",
    "# 03 train my model\n",
    "epoch = 1000 # how many train count?\n",
    "LR = 1e-2 # learning rate -> how many update weight?\n",
    "optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n",
    "\n",
    "for ep in range(epoch):\n",
    "    y_h = model(X_train) # 01 forward : MPL\n",
    "    loss_func = func.binary_cross_entropy(y_h, Y_train)\n",
    "    loss_func_tmp = -(torch.sum(torch.log(y_h**Y_train * (1-y_h)**(1-Y_train)))/331) # 02 loss function\n",
    "    optimizer.zero_grad() # 누적을 막아줌\n",
    "    loss_func.backward() # 03 backward : backpropagation\n",
    "    optimizer.step() # 04 weight update\n",
    "    # print\n",
    "    print(f\"epoch: {ep}, train_loss: {round(loss_func.item(), 3)}, my_loss: {round(loss_func_tmp.item(), 3)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.])\n",
      "tensor([2.])\n",
      "tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.], requires_grad=True)\n",
    "for _ in range(3):\n",
    "    loss = x**2 # 식\n",
    "    loss.backward() # 미분 +=\n",
    "    print(x.grad) # 미분결과\n",
    "    x.grad = None\n",
    "\n",
    "#2\n",
    "#2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
